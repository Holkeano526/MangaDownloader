import asyncio
import os
from crawl4ai import AsyncWebCrawler
from crawl4ai.async_configs import LLMConfig
from crawl4ai.extraction_strategy import LLMExtractionStrategy

async def analyze():
    print("ğŸ” Analizando m440.in...")
    
    # 1. Analizar pÃ¡gina de un capÃ­tulo especÃ­fico
    manga_url = "https://m440.in/manga/kaasan-datte-onna-nandayo/1-m72lg" 
    
    async with AsyncWebCrawler(verbose=True) as crawler:
        print(f"ğŸ“„ Crawling Chapter: {manga_url}")
        result = await crawler.arun(url=manga_url, bypass_cache=True)
        
        if result.success:
            print("âœ… Chapter Page Loaded")
            with open("m440_chapter.html", "w", encoding="utf-8") as f:
                f.write(result.html)
            print("ğŸ’¾ Saved m440_chapter.html")
        else:
            print(f"âŒ Failed to load chapter: {result.error_message}")

    # 3. Test Image Download
    img_url = "https://s1.m440.in/uploads/manga/kaasan-datte-onna-nandayo/chapters/1-m72lg/993_1.jpg"
    print(f"ğŸ–¼ Testing download: {img_url}")
    import aiohttp
    async with aiohttp.ClientSession() as session:
        async with session.get(img_url, headers={"User-Agent": "Mozilla/5.0"}) as resp:
            print(f"Status: {resp.status}")
            if resp.status == 200:
                print("âœ… Image downloadable with simple User-Agent")
            else:
                print("âŒ Image blocked, need Referer?")
                async with session.get(img_url, headers={"User-Agent": "Mozilla/5.0", "Referer": "https://m440.in/"}) as resp2:
                    print(f"Status with Referer: {resp2.status}")

        # 2. Analizar un capÃ­tulo (si encontramos uno en el HTML, lo harÃ© manualmente si no)
        # Voy a asumir una URL de capÃ­tulo probable o tratar de extraerla rÃ¡pido
        # Pero primero quiero ver el HTML del manga para saber cÃ³mo extraer los capÃ­tulos.

if __name__ == "__main__":
    asyncio.run(analyze())
